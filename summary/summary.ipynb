{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## R-squared\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "R-squared (R2) is a number that tells you how well the independent variable(s) in a statistical model explain the variation in the dependent variable.\n",
    "\n",
    "**Range:**\n",
    "\n",
    "0 means your regression explains none of the variability of the data\n",
    "1 means your regression explains the entire variability of the data\n",
    "\n",
    "\n",
    "**Interpretation:**\n",
    "\n",
    "value closer to 1 indicates a better fit of the model.\n",
    "value closer to 0 indicates a poor fit of the model.\n",
    "\n",
    "\n",
    "**Goodness of Fit:**\n",
    "\n",
    "measure the goodness of fit on the model, meaning how well the regression line approximates the real data points\n",
    "\n",
    "\n",
    "**Effect of Adding More Variables:**\n",
    "\n",
    "more factors you include in regression, the higher the R-squared (only if it results in better model)\n",
    "\n",
    "\n",
    "**Example: SAT and GPA:**\n",
    "\n",
    "In the example provided, the value is 0.41, meaning that the SAT scores explain 41% of the variability in GPA scores in the sample. This suggests a moderate relationship between SAT scores and GPA, where other factors likely play a significant role in determining GPA as well.\n",
    "\n",
    "(SAT explained 41% of the variability of the GPA in the sample)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adjusted R-squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Interpretation:**\n",
    "\n",
    "Adjusted R-squared provides a more accurate measure of the goodness of fit, especially when comparing models with a different number of predictors.\n",
    "\n",
    "Unlike R-squared, adjusted R-squared can decrease if the added predictors do not improve the model.\n",
    "\n",
    "\n",
    "#### **Penalizing Complexity:**\n",
    "\n",
    "Adjusted R-squared penalizes the inclusion of unnecessary predictors. This helps prevent overfitting, where a model might appear to perform well on training data by capturing noise rather than the underlying relationship.\n",
    "\n",
    "It is especially useful in multiple regression analysis.\n",
    "\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "Suppose you have two models:\n",
    "\n",
    "Model 1 with an R-squared of **0.8** and **3 predictors**.<br>\n",
    "Model 2 with an R-squared of **0.85** and **10 predictors.**<br>\n",
    "\n",
    "Even though Model 2 has a higher R-squared, the adjusted R-squared might be lower if the additional predictors do not contribute significantly to explaining the variability of the dependent variable.\n",
    "\n",
    "\n",
    "\n",
    "#### **When to Use Adjusted R-squared:**\n",
    "\n",
    "**Comparing Models:** When comparing regression models with a different number of predictors, adjusted R-squared provides a better comparison metric.\n",
    "\n",
    "**Model Selection:** It is useful in the process of model selection to choose a model that balances goodness of fit and model complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## p-value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Definition:**\n",
    "\n",
    "The p-value is the probability of obtaining test results at least as extreme as the observed results, under the assumption that the null hypothesis is true.\n",
    "\n",
    "\n",
    "#### **Interpreting P-values:**\n",
    "\n",
    "**Low p-value (≤ α):** Indicates strong evidence against the null hypothesis, so you reject the null hypothesis.\n",
    "\n",
    "If the p-value for the predictor variable x1 is less than or equal to 0.05, you can conclude that there is a statistically significant relationship between x1 and y. This means x1 is a significant predictor of y in your model.\n",
    "\n",
    "**High p-value (> α):** Indicates weak evidence against the null hypothesis, so you fail to reject the null hypothesis.\n",
    "\n",
    "If the p-value for x1 is greater than 0.05, you cannot conclude that there is a significant relationship between x1 and y. This suggests that x1 may not be a useful predictor in your model.\n",
    "\n",
    "**Common Significance Level (α):** Typically set at 0.05, meaning there is a 5% chance of rejecting the null hypothesis when it is actually true (Type I error).\n",
    "\n",
    "\n",
    "\n",
    "#### **Example:**\n",
    "\n",
    "Suppose you are testing a new drug to see if it is more effective than the existing one.\n",
    "\n",
    "**Null Hypothesis (H0):** The new drug is not more effective than the existing drug.\n",
    "\n",
    "**Alternative Hypothesis (H1):** The new drug is more effective than the existing drug.\n",
    "\n",
    "After conducting the experiment and statistical analysis, you obtain a p-value of 0.03.\n",
    "\n",
    "Since 0.03 is less than the common significance level of 0.05, you reject the null hypothesis and conclude that the new drug is more effective.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F-statistic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used for testing the overall significance of the model\n",
    "\n",
    "lower the f-statistic, the closer to a non-significant model"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
